{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a11af8f",
   "metadata": {},
   "source": [
    "# Extractive question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ff243338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "# model_ckpt = \"albert-xxlarge-v2\" \n",
    "# model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "model_ckpt = \"gaussalgo/xlm-roberta-large_extractive-QA_en-cs\"\n",
    "# model_ckpt = \"gaussalgo/mt5-large-priming-QA_en-cs\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "21deb874",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Co se vÃ¡m lÃ­bilo?\", \"Co se vÃ¡m nelÃ­bilo?\", \"JakÃ© byly postavy?\", \"JakÃ½ byl dÄ›j?\", \"JakÃ© mÃ¡te pocity z filmu?\", \"Jste spokojeni nebo zklamÃ¡ni?\", \"Co si myslÃ­te o Cameronovi?\", \"Co jste mÄ›li dnes k obÄ›du?\"]\n",
    "context = \"\"\"Kinoprojekce 3D. Moment pÅ™ekvapenÃ­ jiÅ¾ sice vyprchal, ale pÅ™esto jde stÃ¡le o bohatou podÃ­vanou s propracovanou logistikou. NejvÃ­ce mÄ› nadchla ukÃ¡zka fantazie moÅ™skÃ©ho svÄ›ta s propojenÃ­m duÅ¡e a pÅ™Ã­rody.ğŸ˜ğŸ‘MajstrÅ¡tyk s podpisem skvÄ›lÃ©ho reÅ¾isÃ©ra mÄ› opÄ›t vyvedl na 3 hodiny z tvrdÃ© reality pozemÅ¡Å¥ana s vÃ½jimkou bojovÃ½ch a ziskuchtivÃ½ch scÃ©n, jeÅ¾ jsou buhuÅ¾el aÅ¾ pÅ™Ã­liÅ¡ aktuÃ¡lnÃ­ a velmi destruktivnÃ­ pro lidskou populaciâ€¦ğŸ˜¢ğŸ˜ğŸ˜•ğŸ¤ª\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "05a38199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Co jste mÄ›li dnes k obÄ›du?</s></s> Kinoprojekce 3D. Moment pÅ™ekvapenÃ­ jiÅ¾ sice vyprchal, ale pÅ™esto jde stÃ¡le o bohatou podÃ­vanou s propracovanou logistikou. NejvÃ­ce mÄ› nadchla ukÃ¡zka fantazie moÅ™skÃ©ho svÄ›ta s propojenÃ­m duÅ¡e a pÅ™Ã­rody.ğŸ˜ğŸ‘MajstrÅ¡tyk s podpisem skvÄ›lÃ©ho reÅ¾isÃ©ra mÄ› opÄ›t vyvedl na 3 hodiny z tvrdÃ© reality pozemÅ¡Å¥ana s vÃ½jimkou bojovÃ½ch a ziskuchtivÃ½ch scÃ©n, jeÅ¾ jsou buhuÅ¾el aÅ¾ pÅ™Ã­liÅ¡ aktuÃ¡lnÃ­ a velmi destruktivnÃ­ pro lidskou populaci...ğŸ˜¢ğŸ˜ğŸ˜•ğŸ¤ª</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(inputs[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b6699ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Kinoprojekce 3D. Moment pÅ™ekvapenÃ­ jiÅ¾ sice vyprchal, ale pÅ™esto jde stÃ¡le o bohatou podÃ­vanou s propracovanou logistikou. NejvÃ­ce mÄ› nadchla ukÃ¡zka fantazie moÅ™skÃ©ho svÄ›ta s propojenÃ­m duÅ¡e a pÅ™Ã­rody.ğŸ˜ğŸ‘MajstrÅ¡tyk s podpisem skvÄ›lÃ©ho reÅ¾isÃ©ra mÄ› opÄ›t vyvedl na 3 hodiny z tvrdÃ© reality pozemÅ¡Å¥ana s vÃ½jimkou bojovÃ½ch a ziskuchtivÃ½ch scÃ©n, jeÅ¾ jsou buhuÅ¾el aÅ¾ pÅ™Ã­liÅ¡ aktuÃ¡lnÃ­ a velmi destruktivnÃ­ pro lidskou populaciâ€¦ğŸ˜¢ğŸ˜ğŸ˜•ğŸ¤ª\n",
      "Question: Co se vÃ¡m lÃ­bilo?\n",
      "\tTop 1 answer: fantazie moÅ™skÃ©ho svÄ›ta s propojenÃ­m duÅ¡e a pÅ™Ã­rody.ğŸ˜ğŸ‘MajstrÅ¡tyk\n",
      "\tTop 2 answer: fantazie moÅ™skÃ©ho svÄ›ta s\n",
      "\tTop 3 answer: Kinoprojekce 3D.\n",
      "Question: Co se vÃ¡m nelÃ­bilo?\n",
      "\tTop 1 answer: Kinoprojekce 3D.\n",
      "\tTop 2 answer: \n",
      "\tTop 3 answer: bojovÃ½ch a ziskuchtivÃ½ch scÃ©n,\n",
      "Question: JakÃ© byly postavy?\n",
      "\tTop 1 answer: \n",
      "\tTop 2 answer: buhuÅ¾el\n",
      "\tTop 3 answer: buhuÅ¾el aÅ¾\n",
      "Question: JakÃ½ byl dÄ›j?\n",
      "\tTop 1 answer: \n",
      "\tTop 2 answer: fantazie\n",
      "\tTop 3 answer: fantazie moÅ™skÃ©ho\n",
      "Question: JakÃ© mÃ¡te pocity z filmu?\n",
      "\tTop 1 answer: pÅ™ekvapenÃ­ jiÅ¾\n",
      "\tTop 2 answer: nadchla ukÃ¡zka\n",
      "\tTop 3 answer: Moment pÅ™ekvapenÃ­ jiÅ¾\n",
      "Question: Jste spokojeni nebo zklamÃ¡ni?\n",
      "\tTop 1 answer: \n",
      "\tTop 2 answer: pÅ™ekvapenÃ­\n",
      "\tTop 3 answer: buhuÅ¾el\n",
      "Question: Co si myslÃ­te o Cameronovi?\n",
      "\tTop 1 answer: \n",
      "\tTop 2 answer: reÅ¾isÃ©ra\n",
      "\tTop 3 answer: reÅ¾isÃ©ra mÄ›\n",
      "Question: Co jste mÄ›li dnes k obÄ›du?\n",
      "\tTop 1 answer: \n",
      "\tTop 2 answer: bohatou\n",
      "\tTop 3 answer: bohatou podÃ­vanou\n"
     ]
    }
   ],
   "source": [
    "print(f\"Context: {context}\")\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "    start_idx = torch.argmax(start_logits)  \n",
    "    end_idx = torch.argmax(end_logits) + 1  \n",
    "    answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "    answer = tokenizer.decode(answer_span)\n",
    "    pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "    answers = pipe(question=question, context=context, topk=3, handle_impossible_answer=True)\n",
    "    \n",
    "    print(f\"Question: {question}\")\n",
    "    for idx, answer in enumerate(answers):\n",
    "        print(f\"\\tTop {idx+1} answer: {answer['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b862855",
   "metadata": {},
   "source": [
    "# Generative question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20a6c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: \n",
      "    Question: Jak se jmenuje prezident? \n",
      "    Context: VÄera jsem mÄ›l rozhovor s novÄ› zvolenÃ½m prezidentem, Petrem Pavlem.\n",
      "    Answer: Petr Pavel \n",
      "    Question: PÅ™i studiu jsem absolvoval mnoho nudnÃ½ch pÅ™edkÃ¡Å¡ek o dÄ›jinÃ¡ch ekonomickÃ©ho myÅ¡lenÃ­.\n",
      "    Context: JakÃ© byly pÅ™ednÃ¡Å¡ky z dÄ›jin ekonomickÃ©ho myÅ¡lenÃ­?\n",
      "    Answer: nudnÃ©\n",
      "    Question: Dnes jsem mÄ›l k obÄ›du kuÅ™ecÃ­ kung pao.\n",
      "    Context: Co jsem mÄ›l dnes k obÄ›du?\n",
      "    Answer: kuÅ™enÃ­ kung pao\n",
      "    Question: Moje oblÃ­benÃ¡ sci-fi kniha je Enderova hra.\n",
      "    Context: JakÃ¡ je moje oblÃ­benÃ¡ sci-fi kniha?\n",
      "    Answer: Enderova hra.\n",
      "    Question: NejradÄ›ji ve volnÃ©m Äase Ätu.\n",
      "    Context: Co dÄ›lÃ¡m nejradÄ›ji ve volnÃ©m Äase?\n",
      "    Answer:\n",
      "Answer:\n",
      "<pad> Ätu</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gaussalgo/mt5-large-priming-QA_en-cs\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"gaussalgo/mt5-large-priming-QA_en-cs\")\n",
    "\n",
    "\n",
    "input_text = \"\"\"\n",
    "    Question: Jak se jmenuje prezident? \n",
    "    Context: VÄera jsem mÄ›l rozhovor s novÄ› zvolenÃ½m prezidentem, Petrem Pavlem.\n",
    "    Answer: Petr Pavel \n",
    "    Question: PÅ™i studiu jsem absolvoval mnoho nudnÃ½ch pÅ™edkÃ¡Å¡ek o dÄ›jinÃ¡ch ekonomickÃ©ho myÅ¡lenÃ­.\n",
    "    Context: JakÃ© byly pÅ™ednÃ¡Å¡ky z dÄ›jin ekonomickÃ©ho myÅ¡lenÃ­?\n",
    "    Answer: nudnÃ©\n",
    "    Question: Dnes jsem mÄ›l k obÄ›du kuÅ™ecÃ­ kung pao.\n",
    "    Context: Co jsem mÄ›l dnes k obÄ›du?\n",
    "    Answer: kuÅ™ecÃ­ kung pao\n",
    "    Question: Moje oblÃ­benÃ¡ sci-fi kniha je Enderova hra.\n",
    "    Context: JakÃ¡ je moje oblÃ­benÃ¡ sci-fi kniha?\n",
    "    Answer: Enderova hra.\n",
    "    Question: NejradÄ›ji ve volnÃ©m Äase Ätu.\n",
    "    Context: Co dÄ›lÃ¡m nejradÄ›ji ve volnÃ©m Äase?\n",
    "    Answer:\"\"\"\n",
    "\n",
    "# For the expected format of input_text, see Intended use above\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs)\n",
    "\n",
    "print(f'Input text: {input_text}')\n",
    "print(\"Answer:\")\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dbc87479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Ätu</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b346a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
