{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b286afb",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8753a9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a84e685fd841afb0a2944e89789679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2d99b6942d46eda87c0123a8b8bc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/890k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7e934fc08c46fb85ea0079ea96bcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/558k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816a0bb891834d539e6f3d75c8a97af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030d7f34bb554c4bbe1812f2d7197987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59070d62a0b4f8ba8bca20b92c648ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/947 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d10b48c979b4b63a714e76652656f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/152M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"fav-kky/gpt2-small-cs\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "247685b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dobrý den, přátelé. Dneska si</td>\n",
       "      <td>myslím (4.09%)</td>\n",
       "      <td>můžete (2.91%)</td>\n",
       "      <td>chci (2.79%)</td>\n",
       "      <td>jdu (2.76%)</td>\n",
       "      <td>na (2.75%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dobrý den, přátelé. Dneska si myslím</td>\n",
       "      <td>, (95.42%)</td>\n",
       "      <td>že (3.34%)</td>\n",
       "      <td>. (0.15%)</td>\n",
       "      <td>, (0.14%)</td>\n",
       "      <td>to (0.07%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dobrý den, přátelé. Dneska si myslím,</td>\n",
       "      <td>že (97.96%)</td>\n",
       "      <td>že (1.23%)</td>\n",
       "      <td>jak (0.06%)</td>\n",
       "      <td>ze (0.06%)</td>\n",
       "      <td>je (0.03%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dobrý den, přátelé. Dneska si myslím, že</td>\n",
       "      <td>to (8.95%)</td>\n",
       "      <td>je (8.16%)</td>\n",
       "      <td>se (5.60%)</td>\n",
       "      <td>by (4.57%)</td>\n",
       "      <td>jsem (3.98%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dobrý den, přátelé. Dneska si myslím, že to</td>\n",
       "      <td>je (15.93%)</td>\n",
       "      <td>bude (13.46%)</td>\n",
       "      <td>není (9.59%)</td>\n",
       "      <td>bylo (7.56%)</td>\n",
       "      <td>byl (4.61%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dobrý den, přátelé. Dneska si myslím, že to je</td>\n",
       "      <td>opravdu (2.80%)</td>\n",
       "      <td>docela (2.25%)</td>\n",
       "      <td>pro (2.13%)</td>\n",
       "      <td>dobrý (2.05%)</td>\n",
       "      <td>tak (2.04%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dobrý den, přátelé. Dneska si myslím, že to je...</td>\n",
       "      <td>velmi (3.88%)</td>\n",
       "      <td>hodně (3.65%)</td>\n",
       "      <td>dobrý (3.07%)</td>\n",
       "      <td>tak (1.81%)</td>\n",
       "      <td>něco (1.61%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dobrý den, přátelé. Dneska si myslím, že to je...</td>\n",
       "      <td>důležité (8.04%)</td>\n",
       "      <td>dobrý (6.09%)</td>\n",
       "      <td>zajímavé (3.58%)</td>\n",
       "      <td>dobrá (3.29%)</td>\n",
       "      <td>důležitý (2.88%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input           Choice 1  \\\n",
       "0                      Dobrý den, přátelé. Dneska si     myslím (4.09%)   \n",
       "1               Dobrý den, přátelé. Dneska si myslím         , (95.42%)   \n",
       "2              Dobrý den, přátelé. Dneska si myslím,        že (97.96%)   \n",
       "3           Dobrý den, přátelé. Dneska si myslím, že         to (8.95%)   \n",
       "4        Dobrý den, přátelé. Dneska si myslím, že to        je (15.93%)   \n",
       "5     Dobrý den, přátelé. Dneska si myslím, že to je    opravdu (2.80%)   \n",
       "6  Dobrý den, přátelé. Dneska si myslím, že to je...      velmi (3.88%)   \n",
       "7  Dobrý den, přátelé. Dneska si myslím, že to je...   důležité (8.04%)   \n",
       "\n",
       "          Choice 2           Choice 3        Choice 4           Choice 5  \n",
       "0   můžete (2.91%)       chci (2.79%)     jdu (2.76%)         na (2.75%)  \n",
       "1       že (3.34%)          . (0.15%)       , (0.14%)         to (0.07%)  \n",
       "2       že (1.23%)        jak (0.06%)      ze (0.06%)         je (0.03%)  \n",
       "3       je (8.16%)         se (5.60%)      by (4.57%)       jsem (3.98%)  \n",
       "4    bude (13.46%)       není (9.59%)    bylo (7.56%)        byl (4.61%)  \n",
       "5   docela (2.25%)        pro (2.13%)   dobrý (2.05%)        tak (2.04%)  \n",
       "6    hodně (3.65%)      dobrý (3.07%)     tak (1.81%)       něco (1.61%)  \n",
       "7    dobrý (6.09%)   zajímavé (3.58%)   dobrá (3.29%)   důležitý (2.88%)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_txt = \"Dobrý den, přátelé. Dneska si\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids=input_ids)\n",
    "        # Select logits of the first batch and the last token and apply softmax\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
    "        # Store tokens with highest probabilities\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "            token_choice = (\n",
    "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
    "            )\n",
    "            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
    "        # Append predicted next token to input\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        iterations.append(iteration)\n",
    "        \n",
    "pd.DataFrame(iterations)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfb69b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dobrý den, přátelé. Dneska si myslím, že to je opravdu velmi důležité\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c0e628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V neuvěřitelném zvratu, vědci objevili, že stádo jednorožců žije v dříve neprobádané oblasti Tibetu. Ještě větší překvapení než samotný objev jednorožců bylo, že tito jednorožci mluví dokonale česky.\n",
      "\n",
      "\n",
      " se v Tibetu nachází v nadmořské výšce kolem 600 metrů. V roce 1850 se v Tibetu narodil první syn a jeho otec. V roce 1850 se v Tibetu narodil první syn a jeho otec. V roce 1850 se v Tibetu narodil první syn a jeho otec. V roce 1850 se v Tibetu narodil první syn a jeho otec. V roce 1850 se v Tibetu\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"V neuvěřitelném zvratu, vědci objevili, že \\\n",
    "stádo jednorožců žije v dříve neprobádané oblasti Tibetu. \\\n",
    "Ještě větší překvapení než samotný objev jednorožců bylo, \\\n",
    "že tito jednorožci mluví dokonale česky.\\n\\n\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length, \n",
    "                               do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271f0c85",
   "metadata": {},
   "source": [
    "# Různé metody generování dalších tokenů"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea7996",
   "metadata": {},
   "source": [
    "Greedy seacch má velkou slabinu v tom, že při výběru nejpravděpodobnějšího dalšího tokenu nedostaneme celkově koherentní větu. Lepší bude beam search, který hledá \"pravděpodobnou\" generovanou větu jako celek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "009556f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def log_probs_from_logits(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "    return logp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5037926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_logprob(model, labels, input_len=0):\n",
    "    with torch.no_grad():\n",
    "        output = model(labels)\n",
    "        log_probs = log_probs_from_logits(\n",
    "            output.logits[:, :-1, :], labels[:, 1:])\n",
    "        seq_log_prob = torch.sum(log_probs[:, input_len:])\n",
    "    return seq_log_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9b57da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V neuvěřitelném zvratu, vědci objevili, že stádo jednorožců žije v dříve neprobádané oblasti Tibetu. Ještě větší překvapení než samotný objev jednorožců bylo, že tito jednorožci mluví dokonale česky.\n",
      "\n",
      "\n",
      " se v Tibetu nachází v nadmořské výšce kolem 600 metrů. V roce 1850 se v Tibetu narodil první syn a jeho otec. V roce 1850 se v Tibetu narodil první syn a jeho otec. V roce 1850 se v Tibetu narodil první syn a jeho otec. V roce 1850 se v Tibetu narodil první syn a jeho otec. V roce 1850 se v Tibetu\n",
      "\n",
      "log-prob: -85.45\n"
     ]
    }
   ],
   "source": [
    "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_greedy[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f589cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V neuvěřitelném zvratu, vědci objevili, že stádo jednorožců žije v dříve neprobádané oblasti Tibetu. Ještě větší překvapení než samotný objev jednorožců bylo, že tito jednorožci mluví dokonale česky.\n",
      "\n",
      "\n",
      ", který se nachází na okraji Tibetu, se nachází na okraji Tibetu, a to na okraji Tibetu, a to na okraji Tibetu, a to na okraji Tibetu, a to na okraji Tibetu, a to na okraji Tibetu, a to na okraji Tibetu, a to na okraji Tibetu, a to na okraji Tibetu, a to na okraji Tibetu, a\n",
      "\n",
      "log-prob: -37.32\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=4, \n",
    "                             do_sample=False)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b571403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V neuvěřitelném zvratu, vědci objevili, že stádo jednorožců žije v dříve neprobádané oblasti Tibetu. Ještě větší překvapení než samotný objev jednorožců bylo, že tito jednorožci mluví dokonale česky.\n",
      "\n",
      "\n",
      ", který se nachází v údolí řeky Tibet, je jedním z nejmocnějších buddhistických chrámů na světě. Je to jeden z mála buddhismů, které se dochovaly dodnes, a to nejen v Číně, ale i v dalších zemích světa.<|endoftext|>\n",
      "\n",
      "log-prob: -81.78\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5, \n",
    "                             do_sample=False, no_repeat_ngram_size=2)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a8419f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V neuvěřitelném zvratu, vědci objevili, že stádo jednorožců žije v dříve neprobádané oblasti Tibetu. Ještě větší překvapení než samotný objev jednorožců bylo, že tito jednorožci mluví dokonale česky.\n",
      "\n",
      "\n",
      " se nachází v jedné z nejvýchodnějších čínských provincií obklopujících se v provincii Karmen. Je to dokonce jeden z mála čínských ostrůvků, kde celá provincie žijí. Na tuto informaci vědci upozornili především proto, že v asijském světě není tolik prostoru pro chov vody, kolik by se mohlo na toto místo určovat, od původního zdroje vody, který tady v minulosti vznikl. Tykadla\n"
     ]
    }
   ],
   "source": [
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True, \n",
    "                             temperature=0.8, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76507300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V neuvěřitelném zvratu, vědci objevili, že stádo jednorožců žije v dříve neprobádané oblasti Tibetu. Ještě větší překvapení než samotný objev jednorožců bylo, že tito jednorožci mluví dokonale česky.\n",
      "\n",
      "\n",
      " z Číny se stal v čínském prostředí prvním člověkem, který se objevil na této planetě. Ten v Tibetu viděl už přes osmdesát pět lidských druhů. Je to vlastně první člověkem v čínském pralese. Tento objev se odehrál před 100 lety, kdy na čínské zdi byla vybudována nová kolonie. To znamená, že tu vyrostlo na téměř tisíc kilometrů čtverečních této oblasti, jejíž plocha měla být až 200 tisíc\n"
     ]
    }
   ],
   "source": [
    "output_topk = model.generate(input_ids, max_length=max_length, do_sample=True, \n",
    "                             top_k=50)\n",
    "print(tokenizer.decode(output_topk[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
